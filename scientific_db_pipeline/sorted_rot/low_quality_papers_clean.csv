paper_id,title,abstract,publication_year,citation_count,rot_score,doi,source_url,quality_group
28,A Joint Model for Question Answering and Question Generation,We propose a generative machine comprehension model that learns jointly to ask and answer questions based on documents. The proposed model uses a sequence-to-sequence framework that encodes the docume...,2017,561,62.33,N/A,http://arxiv.org/abs/1706.01450v1,Low ROT
36,EvoPrompting: Language Models for Code-Level Neural Architecture Search,"Given the recent impressive accomplishments of language models (LMs) for code generation, we explore the use of LMs as adaptive mutation and crossover operators for an evolutionary neural architecture...",2023,180,60.0,N/A,http://arxiv.org/abs/2302.14838v3,Low ROT
38,Early stopping by correlating online indicators in neural networks,"In order to minimize the generalization error in neural networks, a novel technique to identify overfitting phenomena when training the learner is formally introduced. This enables support of a reliab...",2024,107,53.5,N/A,http://arxiv.org/abs/2402.02513v1,Low ROT
40,Poisoning Knowledge Graph Embeddings via Relation Inference Patterns,"We study the problem of generating data poisoning attacks against Knowledge Graph Embedding (KGE) models for the task of link prediction in knowledge graphs. To poison KGE models, we propose to exploi...",2021,257,51.4,N/A,http://arxiv.org/abs/2111.06345v1,Low ROT
16,Adaptive Integrated Layered Attention (AILA),"We propose Adaptive Integrated Layered Attention (AILA), a neural network architecture that combines dense skip connections with different mechanisms for adaptive feature reuse across network layers. ...",2025,48,48.0,N/A,http://arxiv.org/abs/2503.22742v2,Low ROT
27,A Recurrent Neural Model with Attention for the Recognition of Chinese Implicit Discourse Relations,We introduce an attention-based Bi-LSTM for Chinese implicit discourse relations and demonstrate that modeling argument pairs as a joint sequence can outperform word order-agnostic approaches. Our mod...,2017,414,46.0,N/A,http://arxiv.org/abs/1704.08092v1,Low ROT
46,The Ubuntu Dialogue Corpus: A Large Dataset for Research in Unstructured Multi-Turn Dialogue Systems,"This paper introduces the Ubuntu Dialogue Corpus, a dataset containing almost 1 million multi-turn dialogues, with a total of over 7 million utterances and 100 million words. This provides a unique re...",2015,432,39.27,N/A,http://arxiv.org/abs/1506.08909v3,Low ROT
21,Adversarial Attacks on Knowledge Graph Embeddings via Instance Attribution Methods,"Despite the widespread use of Knowledge Graph Embeddings (KGE), little is known about the security vulnerabilities that might disrupt their intended behaviour. We study data poisoning attacks against ...",2021,184,36.8,N/A,http://arxiv.org/abs/2111.03120v1,Low ROT
47,Building End-To-End Dialogue Systems Using Generative Hierarchical Neural Network Models,"We investigate the task of building open domain, conversational dialogue systems based on large dialogue corpora using generative models. Generative models produce system responses that are autonomous...",2015,340,30.91,N/A,http://arxiv.org/abs/1507.04808v3,Low ROT
10,Creating Trustworthy LLMs: Dealing with Hallucinations in Healthcare AI,Large language models have proliferated across multiple domains in as short period of time. There is however hesitation in the medical and healthcare domain towards their adoption because of issues li...,2023,87,29.0,N/A,http://arxiv.org/abs/2311.01463v1,Low ROT
34,Large Language Models and Emergence: A Complex Systems Perspective,"Emergence is a concept in complexity science that describes how many-body systems manifest novel higher-level properties, properties that can be described by replacing high-dimensional mechanisms with...",2025,25,25.0,N/A,http://arxiv.org/abs/2506.11135v1,Low ROT
23,Continual Learning of Natural Language Processing Tasks: A Survey,Continual learning (CL) is a learning paradigm that emulates the human capability of learning and accumulating knowledge continually without forgetting the previously learned knowledge and also transf...,2022,100,25.0,N/A,http://arxiv.org/abs/2211.12701v2,Low ROT
43,Exponentially Faster Language Modelling,"Language models only really need to use an exponential fraction of their neurons for individual inferences. As proof, we present UltraFastBERT, a BERT variant that uses 0.3% of its neurons during infe...",2023,73,24.33,N/A,http://arxiv.org/abs/2311.10770v2,Low ROT
8,Large Language Model Guided Tree-of-Thought,"In this paper, we introduce the Tree-of-Thought (ToT) framework, a novel approach aimed at improving the problem-solving capabilities of auto-regressive large language models (LLMs). The ToT technique...",2023,67,22.33,N/A,http://arxiv.org/abs/2305.08291v1,Low ROT
35,TextConvoNet:A Convolutional Neural Network based Architecture for Text Classification,"In recent years, deep learning-based models have significantly improved the Natural Language Processing (NLP) tasks. Specifically, the Convolutional Neural Network (CNN), initially used for computer v...",2022,87,21.75,N/A,http://arxiv.org/abs/2203.05173v1,Low ROT
11,Liquid Structural State-Space Models,"A proper parametrization of state transition matrices of linear state-space models (SSMs) followed by standard nonlinearities enables them to efficiently learn representations from sequential data, es...",2022,86,21.5,N/A,http://arxiv.org/abs/2209.12951v1,Low ROT
3,Show me your NFT and I tell you how it will perform: Multimodal representation learning for NFT sell...,"Non-Fungible Tokens (NFTs) represent deeds of ownership, based on blockchain technologies and smart contracts, of unique crypto assets on digital art forms (e.g., artworks or collectibles). In the spo...",2023,64,21.33,N/A,http://arxiv.org/abs/2302.01676v2,Low ROT
14,QTN-VQC: An End-to-End Learning framework for Quantum Neural Networks,"The advent of noisy intermediate-scale quantum (NISQ) computers raises a crucial challenge to design quantum neural networks for fully quantum learning tasks. To bridge the gap, this work proposes an ...",2021,98,19.6,N/A,http://arxiv.org/abs/2110.03861v3,Low ROT
15,STL: A Signed and Truncated Logarithm Activation Function for Neural Networks,"Activation functions play an essential role in neural networks. They provide the non-linearity for the networks. Therefore, their properties are important for neural networks' accuracy and running per...",2023,50,16.67,N/A,http://arxiv.org/abs/2307.16389v1,Low ROT
9,From Neural Activations to Concepts: A Survey on Explaining Concepts in Neural Networks,"In this paper, we review recent approaches for explaining concepts in neural networks. Concepts can act as a natural link between learning and reasoning: once the concepts are identified that a neural...",2023,49,16.33,N/A,http://arxiv.org/abs/2310.11884v2,Low ROT
12,Symbolic Discovery of Optimization Algorithms,"We present a method to formulate algorithm discovery as program search, and apply it to discover optimization algorithms for deep neural network training. We leverage efficient search techniques to ex...",2023,47,15.67,N/A,http://arxiv.org/abs/2302.06675v4,Low ROT
31,Formal Algorithms for Transformers,"This document aims to be a self-contained, mathematically precise overview of transformer architectures and algorithms (*not* results). It covers what transformers are, how they are trained, what they...",2022,60,15.0,N/A,http://arxiv.org/abs/2207.09238v1,Low ROT
13,LLM2TEA: Agentic AI Designer Finds Innovative Objects with Generative Evolutionary Multitasking,"In this paper, we introduce LLM-driven MultiTask Evolutionary Algorithm (LLM2TEA), the first agentic AI designer within a generative evolutionary multitasking (GEM) framework that promotes the crossov...",2024,27,13.5,N/A,http://arxiv.org/abs/2406.14917v2,Low ROT
24,EvoGPT-f: An Evolutionary GPT Framework for Benchmarking Formal Math Languages,Formal mathematics is the discipline of translating mathematics into a programming language in which any statement can be unequivocally checked by a computer. Mathematicians and computer scientists ha...,2024,16,8.0,N/A,http://arxiv.org/abs/2402.16878v1,Low ROT
32,HULAT at SemEval-2023 Task 9: Data augmentation for pre-trained transformers applied to Multilingual...,"This paper describes our participation in SemEval-2023 Task 9, Intimacy Analysis of Multilingual Tweets. We fine-tune some of the most popular transformer models with the training dataset and syntheti...",2023,15,5.0,N/A,http://arxiv.org/abs/2302.12794v1,Low ROT
